{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivated by the decreasing pattern visualized on the yearly distribution of the taxi pickups in New York, we started to research about the phenomena. After finding out that the causant was other ride-hailing companies we decided to study it deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data\n",
    "The dataset contains, roughly, four groups of files:\n",
    "\n",
    "Uber trip data from 2014 (April - September), separated by month, with detailed location information\n",
    "\n",
    "There are six files of raw data on Uber pickups in New York City from April to September 2014. The files are separated by month and each has the following columns:\n",
    "\n",
    "Date/Time : The date and time of the Uber pickup\n",
    "Lat : The latitude of the Uber pickup\n",
    "Lon : The longitude of the Uber pickup\n",
    "Base : The TLC base company code affiliated with the Uber pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(\"../project/nyc-taxi-trip-duration\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did with the main code we will explain part by part instead of grouping in different topics. Since, we were creating new analysis as soon as we were advancing with the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sodapy import Socrata\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import random\n",
    "import os\n",
    "import folium \n",
    "from folium.plugins import *\n",
    "\n",
    "path='../project/'\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "client = Socrata(\"data.cityofnewyork.us\",\n",
    "                 \"Hi16i3SK4y2UNiONqpKz4IROh\",\n",
    "                 username=\"**************\",\n",
    "                 password=\"**************\",\n",
    "                 timeout=120)\n",
    "#https://data.cityofnewyork.us/resource/gkne-dk5s.json\n",
    "# First 2000 results, returned as JSON from API / converted to Python list of\n",
    "# dictionaries by sodapy.\n",
    "results = client.get(\"gkne-dk5s\", limit=3000000) #Uber rows without NaN\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_taxi = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following lines of code we are going to adequate the code for the studies that comes in continuation and also filter the taxi and uber dataset columns to contain the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi['pickup_datetime'] = pd.to_datetime(df_taxi['pickup_datetime'],format = '%Y-%m-%dT%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = df_taxi.iloc[:,[1,5,6,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for the uber dataset timeline\n",
    "df_taxi = df_taxi[df_taxi[\"pickup_datetime\"].dt.month>3]\n",
    "df_taxi = df_taxi[df_taxi[\"pickup_datetime\"].dt.month<10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split date/time column\n",
    "df_taxi['pickup_datetime'] = pd.to_datetime(df_taxi['pickup_datetime'].copy())        \n",
    "#df_taxi['Year'] = df_taxi['pickup_datetime'].dt.year\n",
    "df_taxi['Month'] = df_taxi['pickup_datetime'].dt.month\n",
    "df_taxi['MonthDay'] = df_taxi['pickup_datetime'].dt.day\n",
    "df_taxi['DayOfWeek'] = df_taxi['pickup_datetime'].dt.dayofweek\n",
    "df_taxi['HourOfDay'] = df_taxi['pickup_datetime'].dt.hour\n",
    "df_taxi[\"HourOfWeek\"] = (df_taxi[\"DayOfWeek\"]*24 )+df_taxi[\"HourOfDay\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi.drop(['pickup_datetime'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi=df_taxi.iloc[:,[1,0,2,3,4,5,6]]\n",
    "df_taxi.rename(columns={\"pickup_latitude\": \"Lat\", \"pickup_longitude\": \"Lon\"},inplace=True)\n",
    "df_taxi['Lon']=df_taxi['Lon'].apply(lambda x: float(x))\n",
    "df_taxi['Lat']=df_taxi['Lat'].apply(lambda x: float(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create uber dataset\n",
    "df_uber = (pd.read_csv(path+'uber/uber-raw-data-apr14.csv')\n",
    "           .append(pd.read_csv(path+'uber/uber-raw-data-may14.csv'))\n",
    "           .append(pd.read_csv(path+'uber/uber-raw-data-jun14.csv'))\n",
    "           .append(pd.read_csv(path+'uber/uber-raw-data-jul14.csv'))\n",
    "           .append(pd.read_csv(path+'uber/uber-raw-data-aug14.csv'))\n",
    "           .append(pd.read_csv(path+'uber/uber-raw-data-sep14.csv')))\n",
    "df_uber = df_uber[df_uber['Lat'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set time to pamdas datetime format.\n",
    "df_uber['Date/Time'] = pd.to_datetime(df_uber['Date/Time'],format = '%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split date/time column\n",
    "df_uber['Date/Time'] = pd.to_datetime(df_uber['Date/Time'].copy())        \n",
    "#df_uber['Year'] = df_uber['Date/Time'].dt.year\n",
    "df_uber['Month'] = df_uber['Date/Time'].dt.month\n",
    "df_uber['MonthDay'] = df_uber['Date/Time'].dt.day\n",
    "df_uber['DayOfWeek'] = df_uber['Date/Time'].dt.dayofweek\n",
    "df_uber['HourOfDay'] = df_uber['Date/Time'].dt.hour\n",
    "df_uber[\"HourOfWeek\"] = (df_uber[\"DayOfWeek\"]*24 )+df_uber[\"HourOfDay\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uber.drop(['Date/Time','Base'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uber=df_uber.sample(len(df_taxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi-Uber Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the main code, the following analysis will have a lot of time distributions. Therefore, it was decided to create a plot function in order to have the keep the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grouped_plot(x_taxi,x_uber,Index_list,label_plot,version):\n",
    "    if version == 1:\n",
    "        # set width of bars\n",
    "        barWidth = 0.3\n",
    "\n",
    "        # set heights of bars\n",
    "        bars1 = list(x_taxi)\n",
    "        bars2 = list(x_uber)\n",
    "\n",
    "\n",
    "        # Set position of bar on X axis\n",
    "        r1 = np.arange(len(bars1))\n",
    "        r2 = [x + barWidth for x in r1]\n",
    "\n",
    "\n",
    "        # Make the plot\n",
    "\n",
    "        plt.figure(figsize = [12, 6])\n",
    "\n",
    "        plt.bar(r1, x_taxi, width=barWidth,  label='Taxi', alpha=0.5, color='yellow')\n",
    "        plt.bar(r2, x_uber, width=barWidth,  label='Uber', alpha=0.5, color='black')\n",
    "\n",
    "        plt.xlabel(label_plot)\n",
    "        plt.ylabel('Proportion %  ')\n",
    "        title_plot=label_plot+' PickUps distribution'\n",
    "        plt.title(title_plot)\n",
    "\n",
    "        # Add xticks on the middle of the group bars\n",
    "        plt.xlabel(label_plot, fontweight='bold')\n",
    "        plt.xticks([r + barWidth for r in range(len(bars1))], Index_list)\n",
    "    \n",
    "    else:\n",
    "        # set heights of bars\n",
    "        bars1 = list(x_taxi)\n",
    "        bars2 = list(x_uber)        \n",
    "        \n",
    "        # Set position of bar on X axis\n",
    "        r1 = np.arange(len(bars1))\n",
    "        r2 = np.arange(len(bars2))\n",
    "\n",
    "\n",
    "        #plot\n",
    "        plt.figure(figsize = [12, 6])\n",
    "        ax = plt.bar(r1, x_taxi,  label='Taxi', alpha=0.5);\n",
    "        ax = plt.bar(r1, x_uber,  label='Uber', alpha=0.5)\n",
    "        #plt.legend(labels = ['DISORDERLY CONDUCT', 'RECOVERED VEHICLE']);\n",
    "\n",
    "        plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "        # Create legend & Show graphic\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualizations with histogram between Uber in black and Taxis in Yellow make easy to compare the differences in the time distributions. Being automatic to obtain the different insight underlying in these patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dayhour_taxi = df_taxi.groupby(\"HourOfDay\")[\"HourOfDay\"].count()\n",
    "df_dayhour_taxi=pd.DataFrame(df_dayhour_taxi/df_dayhour_taxi.sum())\n",
    "df_dayhour_uber = df_uber.groupby(\"HourOfDay\")[\"HourOfDay\"].count()\n",
    "df_dayhour_uber=pd.DataFrame(df_dayhour_uber/df_dayhour_uber.sum())\n",
    "\n",
    "df_dayhour = pd.DataFrame({'Taxi':  df_dayhour_taxi['HourOfDay'].to_list(),\n",
    "                   'Uber': df_dayhour_uber['HourOfDay'].to_list()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Grouped_plot(df_dayhour['Taxi'].values,df_dayhour['Uber'].values,\n",
    "             df_dayhour.index.to_list(),'Hour of the Day',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday_taxi = df_taxi.groupby(\"DayOfWeek\")[\"DayOfWeek\"].count()\n",
    "df_weekday_taxi=pd.DataFrame(df_weekday_taxi/df_weekday_taxi.sum())\n",
    "df_weekday_uber = df_uber.groupby(\"DayOfWeek\")[\"DayOfWeek\"].count()\n",
    "df_weekday_uber=pd.DataFrame(df_weekday_uber/df_weekday_uber.sum())\n",
    "\n",
    "df_weekday = pd.DataFrame({'Taxi':  df_weekday_taxi['DayOfWeek'].to_list(),\n",
    "                   'Uber': df_weekday_uber['DayOfWeek'].to_list()},\n",
    "                       index=[ 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
    "                              'Friday', 'Saturday', 'Sunday' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Grouped_plot(df_weekday['Taxi'].values,df_weekday['Uber'].values,\n",
    "             df_weekday.index.to_list(),'Week Days',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekhour_taxi = df_taxi.groupby(\"HourOfWeek\")[\"HourOfWeek\"].count()\n",
    "df_weekhour_taxi=pd.DataFrame(df_weekhour_taxi/df_weekhour_taxi.sum())\n",
    "df_weekhour_uber = df_uber.groupby(\"HourOfWeek\")[\"HourOfWeek\"].count()\n",
    "df_weekhour_uber=pd.DataFrame(df_weekhour_uber/df_weekhour_uber.sum())\n",
    "\n",
    "df_weekhour = pd.DataFrame({'Taxi':  df_weekhour_taxi['HourOfWeek'].to_list(),\n",
    "                   'Uber': df_weekhour_uber['HourOfWeek'].to_list()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Grouped_plot(df_weekhour['Uber'].values,df_weekhour['Taxi'].values,\n",
    "             df_weekhour.index.to_list(),'Week Hours',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month_taxi = df_taxi.groupby(\"Month\")[\"Month\"].count()\n",
    "df_month_taxi=pd.DataFrame(df_month_taxi/df_month_taxi.sum())\n",
    "df_month_uber = df_uber.groupby(\"Month\")[\"Month\"].count()\n",
    "df_month_uber=pd.DataFrame(df_month_uber/df_month_uber.sum())\n",
    "\n",
    "df_month = pd.DataFrame({'Taxi':  df_month_taxi['Month'].to_list(),\n",
    "                   'Uber': df_month_uber['Month'].to_list()},\n",
    "                       index=[ 'April', 'May', 'June', 'July',\n",
    "                              'Augost', 'September'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Grouped_plot(df_month['Taxi'].values,df_month['Uber'].values,\n",
    "             df_month.index.to_list(),'Month',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to try a more interactive visualization, we tried to do something similar in plotly. However, the result was not as good as the previous simple figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 1\n",
    "fig = make_subplots( rows=rows, cols=cols, subplot_titles=['Taxi Hour Distribution','Uber  Hour Distribution, Comparison'],\n",
    "vertical_spacing=0.1, horizontal_spacing=0.10)\n",
    "\n",
    "#hour\n",
    "fig.add_trace(go.Bar(x=df_dayhour.index.to_list(),\n",
    "                       y=df_dayhour_taxi['HourOfDay']), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=df_dayhour.index.to_list(),\n",
    "                       y=df_dayhour_uber['HourOfDay']), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=df_dayhour.index.to_list(),\n",
    "                       y=df_dayhour_taxi['HourOfDay']), row=3, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=df_dayhour.index.to_list(),\n",
    "                       y=df_dayhour_uber['HourOfDay']), row=3, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(height=1000, width=900, showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 1\n",
    "fig = make_subplots( rows=rows, cols=cols, subplot_titles=['Taxi Hour Distribution','Uber  Hour Distribution, Comparison'],\n",
    "vertical_spacing=0.1, horizontal_spacing=0.10)\n",
    "\n",
    "#weekdays\n",
    "fig.add_trace(go.Bar(x=[ 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
    "                              'Friday', 'Saturday', 'Sunday' ],\n",
    "                       y=df_weekday_taxi['DayOfWeek']), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=[ 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
    "                              'Friday', 'Saturday', 'Sunday' ],\n",
    "                       y=df_weekday_uber['DayOfWeek']), row=2, col=1)\n",
    "fig.add_trace(go.Bar(x=[ 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
    "                              'Friday', 'Saturday', 'Sunday' ],\n",
    "                       y=df_weekday_taxi['DayOfWeek']), row=3, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=[ 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
    "                              'Friday', 'Saturday', 'Sunday' ],\n",
    "                       y=df_weekday_uber['DayOfWeek']), row=3, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(height=1000, width=900, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "rows = 3\n",
    "cols = 1\n",
    "fig = make_subplots( rows=rows, cols=cols, subplot_titles=['Taxi Hour Distribution','Uber  Hour Distribution, Comparison'],\n",
    "vertical_spacing=0.1, horizontal_spacing=0.10)\n",
    "\n",
    "#weekdays\n",
    "fig.add_trace(go.Bar(x= df_month.index.to_list(),\n",
    "                       y=df_month_taxi['Month']), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=df_month.index.to_list(),\n",
    "                       y=df_month_uber['Month']), row=2, col=1)\n",
    "fig.add_trace(go.Bar(x= df_month.index.to_list(),\n",
    "                       y=df_month_taxi['Month']), row=3, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=df_month.index.to_list(),\n",
    "                       y=df_month_uber['Month']), row=3, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=1000, width=900, showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the main code, the week hourly distribution was turned into a bokeh were it was easy to select the day we wanted to visualize. This make it easier to compare day by day what happens to the behaviour of the different transport methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_notebook() # open the bokeh viz on the notebook.\n",
    "## it is a standard way to convert your df to bokeh\n",
    "source_taxi = ColumnDataSource(df_grouped_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_taxi = figure(x_range=FactorRange(factors=list(map(str, (df_grouped_taxi.index+1).values.tolist()))), \n",
    "           plot_height=400, plot_width=800, title='Hourly Week Days Distribution Taxi',\n",
    "           x_axis_label='Hour of the Day', y_axis_label='Proportioned Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = palettes.Category20[len(weekday_list)]\n",
    "bar ={} # to store vbars\n",
    "items = []\n",
    "### here we will do a for loop:\n",
    "for indx,i in enumerate(weekday_list):\n",
    "    bar[i] = p_taxi.line(x='Hours', \n",
    "                    y=i, \n",
    "                    source=source_taxi, \n",
    "                    width=0.9,\n",
    "                    muted=True, \n",
    "                    muted_alpha=0.005,\n",
    "                    color=color[indx])\n",
    "    items.append((i, [bar[i]]))\n",
    "    \n",
    "legend = Legend(items=items)\n",
    "p_taxi.add_layout(legend, 'left')\n",
    "p_taxi.legend.click_policy = 'mute'\n",
    "p_taxi.legend.label_text_font_size='7pt'\n",
    "show(p_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_file('plot_taxi.html', mode='inline')\n",
    "save(p_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = file_html(p_taxi, CDN, \"my plot\")\n",
    "with open(\"./plot_taxi.html\",\"w+\") as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uber['index']=df_uber.index\n",
    "df_grouped_uber = pd.pivot_table(df_uber, index = \"HourOfDay\", \n",
    "                            columns = \"DayOfWeek\",values = 'index' ,aggfunc = 'count')\n",
    "\n",
    "weekday_list=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\",\n",
    "                    \"Friday\", \"Saturday\", \"Sunday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_uber = df_grouped_uber.div(df_grouped_uber.sum(axis=0), axis=1)\n",
    "\n",
    "# Create Hour of the day column as the pivot_table Pandas function converts the HourOfTheDay column to an index.\n",
    "# We need Hour of the day as a separate column to be handed to Bokeh.\n",
    "df_grouped_uber.columns=weekday_list\n",
    "df_grouped_uber['Hours']=df_grouped_uber.index.values\n",
    "display(df_grouped_uber.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_notebook() # open the bokeh viz on the notebook.\n",
    "## it is a standard way to convert your df to bokeh\n",
    "source_uber = ColumnDataSource(df_grouped_uber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_uber = figure(x_range=FactorRange(factors=list(map(str, (df_grouped_uber.index+1).values.tolist()))), \n",
    "           plot_height=400, plot_width=800, title='Hourly Week Days Distribution Uber',\n",
    "           x_axis_label='Hour of the Day', y_axis_label='Proportioned Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = palettes.Category20[len(weekday_list)]\n",
    "bar ={} # to store vbars\n",
    "items = []\n",
    "### here we will do a for loop:\n",
    "for indx,i in enumerate(weekday_list):\n",
    "    bar[i] = p_uber.line(x='Hours', \n",
    "                    y=i, \n",
    "                    source=source_uber, \n",
    "                    width=0.9,\n",
    "                    muted=True, \n",
    "                    muted_alpha=0.005,\n",
    "                    color=color[indx])\n",
    "    items.append((i, [bar[i]]))\n",
    "    \n",
    "legend = Legend(items=items)\n",
    "p_uber.add_layout(legend, 'left')\n",
    "p_uber.legend.click_policy = 'mute'\n",
    "p_uber.legend.label_text_font_size='7pt'\n",
    "show(p_uber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.embed import server_document\n",
    "script = server_document(\"https://demo.bokeh.org/slider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_file('plot_uber.html', mode='inline')\n",
    "save(p_uber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = file_html(p_uber, CDN, \"my plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./plot_uber.html\",\"w+\") as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we decide to check different visualization methods in order to show the geographical patterns of the different transport companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we implemented the different pick up locations on a folium heatmap, so that we can see the range and the concentration of the spatial distribution of each of the datasets. And then we did the same but in seaborn. However, as we did with the main code at the end the spatial distribution was visualized in plotly heatmap which gave a sharp and detailed image. In order to achieve that it was used DTU HPC due to the required computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate folium San Francisco base map with Stamen toner tile \"\"\"\n",
    "def generateBaseMap(default_location=[40.767937,-73.982155], default_zoom_start=10):\n",
    "    base_map = folium.Map(location=default_location, control_scale=True, \n",
    "                          zoom_start=default_zoom_start, tiles=\"Stamen toner\")\n",
    "    return base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creates array of coordinates to input folium map marker map\"\"\"\n",
    "def to_coordinates(row):\n",
    "    return [row[\"Lat\"],row[\"Lon\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi['Coor']=df_taxi.apply(to_coordinates,axis=1)\n",
    "df_uber['Coor']=df_uber.apply(to_coordinates,axis=1)\n",
    "data_HM_taxi=df_taxi[['Lat', 'Lon', 'Coor']].groupby(['Lat', 'Lon']).count().reset_index().values.tolist()\n",
    "data_HM_uber=df_uber[['Lat', 'Lon', 'Coor']].groupby(['Lat', 'Lon']).count().reset_index().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mock for heatmap intensity\n",
    "max_val=max(df_taxi[['Lat', 'Lon', 'Coor']].groupby(['Lat', 'Lon'])\n",
    "            .count().reset_index()['Coor'].values)\n",
    "data_HM_uber.insert(0, [float(90),float(40),float(max_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_map_taxi = generateBaseMap()\n",
    "\n",
    "HeatMap(data=df_taxi['Coor'], \n",
    "        radius=10, max_zoom=12).add_to(base_map_taxi)\n",
    "base_map_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_map_uber = generateBaseMap()\n",
    "HeatMap(data=df_uber['Coor'], \n",
    "        radius=10, max_zoom=12,\n",
    "        ).add_to(base_map_uber)\n",
    "base_map_uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#euclidian distances introduce errors. Therefore, we bin with haversine functions.\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "\n",
    "# remove wrong data.\n",
    "#plt.hist(df['X'], bins='auto')\n",
    "#plt.hist(df['Y'], bins='auto')\n",
    "indexNames = df_uber[(df_uber['Lon'] < -74.08) |(df_uber['Lon'] > -73.84) | (df_uber['Lat'] > 40.86)| (df_uber['Lat'] < 40.60)].index\n",
    "df_uber_drop=df_uber.drop(indexNames)\n",
    "#plt.hist(df['X'], bins='auto')\n",
    "#plt.hist(df['Y'], bins='auto')\n",
    "#bin estimation\n",
    "lat_min = df_uber_drop['Lat'].min()\n",
    "lat_max = df_uber_drop['Lat'].max()\n",
    "lon_min = df_uber_drop['Lon'].min()\n",
    "lon_max = df_uber_drop['Lon'].max()\n",
    "yharvesine=(10/2)*(haversine(lon_min, lat_min, lon_min, lat_max)+haversine(lon_max, lat_min, lon_max, lat_max))\n",
    "xharvesine=(10/2)*(haversine(lon_min, lat_max, lon_max, lat_max)+haversine(lon_min, lat_min, lon_max, lat_min))\n",
    "\n",
    "count, lon, lat = np.histogram2d(df_uber_drop.Lat, df_uber_drop.Lon, bins = [int(xharvesine),int(yharvesine)])\n",
    "\n",
    "#coordinates = df[['Lon', 'Lat']]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax= plt.imshow(count, cmap='magma',vmax=500, origin='lower')\n",
    "\n",
    "plt.grid(b=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove wrong data.\n",
    "#plt.hist(df['X'], bins='auto')\n",
    "#plt.hist(df['Y'], bins='auto')\n",
    "indexNames = df_taxi[(df_taxi['Lon'] < -74.08) |(df_taxi['Lon'] > -73.84) | (df_taxi['Lat'] > 40.86)| (df_taxi['Lat'] < 40.60)].index\n",
    "df_taxi_drop=df_taxi.drop(indexNames)\n",
    "#plt.hist(df['X'], bins='auto')\n",
    "#plt.hist(df['Y'], bins='auto')\n",
    "#bin estimation\n",
    "\n",
    "yharvesine=(10/2)*(haversine(lon_min, lat_min, lon_min, lat_max)+haversine(lon_max, lat_min, lon_max, lat_max))\n",
    "xharvesine=(10/2)*(haversine(lon_min, lat_max, lon_max, lat_max)+haversine(lon_min, lat_min, lon_max, lat_min))\n",
    "\n",
    "count, lon, lat = np.histogram2d(df_taxi_drop.Lat, df_taxi_drop.Lon, bins = [int(xharvesine),int(yharvesine)])\n",
    "\n",
    "#coordinates = df[['Lon', 'Lat']]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax= plt.imshow(count, cmap='magma',vmax=(500/(df_uber_drop.shape[0]/df_taxi_drop.shape[0])), origin='lower') \n",
    "#vmax 500/4 - 4 times less observations after dropping\n",
    "\n",
    "plt.grid(b=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prep_data_uber = df_uber[['Lat', 'Lon','HourOfWeek']]\n",
    "prep_data_uber = prep_data_uber.dropna(axis=0, subset=['Lat', 'Lon','HourOfWeek'])\n",
    "Uber_timeline = [[[row['Lat'],row['Lon']] for index, row in prep_data_uber[prep_data_uber['HourOfWeek'] == i].iterrows()] for i in range(0,166)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = folium.Map([40.767937,-73.982155], tiles='Stamen Toner', zoom_start=10)\n",
    "HeatMapWithTime(Uber_timeline, auto_play=True,\n",
    "                             radius=6).add_to(base_map)\n",
    "display(base_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data_taxi = df_taxi[['Lat', 'Lon','HourOfWeek']]\n",
    "prep_data_taxi = prep_data_taxi.dropna(axis=0, subset=['Lat', 'Lon','HourOfWeek'])\n",
    "taxi_timeline = [[[row['Lat'],row['Lon']] for index, row in prep_data_taxi[prep_data_taxi['HourOfWeek'] == i].iterrows()] for i in range(0,166)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = folium.Map([40.767937,-73.982155], tiles='Stamen Toner', zoom_start=10)\n",
    "HeatMapWithTime(taxi_timeline, auto_play=True,\n",
    "                             radius=6).add_to(base_map)\n",
    "display(base_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section a we tried to predict from a given location and time, if a person was going to ask a taxi or Uber. However, after balancing data and preprocess the values, the grid is entirelly blue. Meaning that everyone ask for Uber not being precise and therefore not being added to the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_taxi_drop=df_taxi_drop.reset_index(drop=True).iloc[:,[0,1,4,5]]\n",
    "df_uber_drop=df_uber_drop.sample(df_taxi_drop.shape[0]).reset_index(drop=True).iloc[:,[0,1,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=100\n",
    "df_taxi_drop=df_taxi_drop.sample(sample)\n",
    "df_uber_drop=df_uber_drop.sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_drop.loc[:,'Category']=np.ones(df_taxi_drop.shape[0],dtype=int)\n",
    "df_uber_drop.loc[:,'Category']=np.zeros(df_uber_drop.shape[0],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_knn=df_taxi_drop.append(df_uber_drop, ignore_index=True)\n",
    "x_train=df_knn.iloc[:,[0,1,2,3]].to_numpy()\n",
    "y_train=df_knn.iloc[:,4].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid with numpy histogram2d\n",
    "_, xedges, yedges = np.histogram2d(df_knn[\"Lon\"], df_knn[\"Lat\"], bins=[50,50])\n",
    "# Get the x,y coordinate of the center of the points\n",
    "x_coord = xedges[1:] - (xedges[1]-xedges[0])\n",
    "y_coord = yedges[1:] - (yedges[1]-yedges[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_points = np.array([[0,0,0,0]])\n",
    "for d in range(7):\n",
    "    for h in range(24):\n",
    "        for x in x_coord:\n",
    "            for y in y_coord:\n",
    "                X_points =  np.append(X_points,[[x,y,d,h]],axis=0)\n",
    "X_points = X_points[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Assigns a color based on the category of the crime\"\"\"\n",
    "def assigncolor(category):\n",
    "    if category == 1.0:\n",
    "        return \"yellow\"#taxi\n",
    "    if category == 0.0:\n",
    "        return \"blue\" #uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "model.fit(x_train, y_train)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1,max_depth=1)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day=6\n",
    "Hour=19\n",
    "X_points_pd=pd.DataFrame(X_points)\n",
    "X_points_pd=X_points_pd[(X_points_pd[2]==Day) & (X_points_pd[3]==Hour)].to_numpy()\n",
    "predicted = model.predict(X_points_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create folium map for 5 KNN\n",
    "base_map = generateBaseMap()\n",
    "for i in range(len(predicted)):\n",
    "        x = X_points_pd[i][0]\n",
    "        y = X_points_pd[i][1]\n",
    "        color = assigncolor(predicted[i])\n",
    "        folium.Circle([y, x], radius=70, fill_opacity=1.0,\n",
    "                     fill_color=color, color=color).add_to(base_map)\n",
    "base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
